#!/usr/bin/env python3
# Script pour utiliser un mod√®le GGUF local avec MLX
# Utilisation : python use_local_model.py --gguf /path/to/model.gguf --prompt "Votre prompt"

import argparse
import time
from pathlib import Path

import mlx.core as mx
import models


def main():
    parser = argparse.ArgumentParser(description="Utiliser un mod√®le GGUF local avec MLX")
    parser.add_argument(
        "--gguf",
        type=str,
        required=True,
        help="Chemin vers le fichier GGUF local"
    )
    parser.add_argument(
        "--prompt",
        type=str,
        default="Bonjour, comment √ßa va ?",
        help="Le prompt √† traiter"
    )
    parser.add_argument(
        "--max-tokens",
        type=int,
        default=100,
        help="Nombre maximum de tokens √† g√©n√©rer"
    )
    parser.add_argument(
        "--temp",
        type=float,
        default=0.0,
        help="Temp√©rature d'√©chantillonnage"
    )
    parser.add_argument(
        "--seed",
        type=int,
        default=0,
        help="Graine al√©atoire"
    )
    
    args = parser.parse_args()
    
    # V√©rifier que le fichier existe
    if not Path(args.gguf).exists():
        print(f"‚ùå Erreur: Le fichier {args.gguf} n'existe pas")
        return
    
    print(f"üîÑ Chargement du mod√®le depuis : {args.gguf}")
    
    # Configurer la graine al√©atoire
    mx.random.seed(args.seed)
    
    # Charger le mod√®le (sans repo car le fichier existe d√©j√†)
    model, tokenizer = models.load(args.gguf, repo=None)
    
    print(f"\nüìù Prompt: {args.prompt}")
    print("ü§ñ R√©ponse: ", end="", flush=True)
    
    # Encoder le prompt
    prompt_tokens = tokenizer.encode(args.prompt)
    
    # G√©n√©ration
    tic = time.time()
    tokens = []
    skip = 0
    
    for token, n in zip(
        models.generate(prompt_tokens, model, args.temp),
        range(args.max_tokens),
    ):
        if token == tokenizer.eos_token_id:
            break
            
        if n == 0:
            prompt_time = time.time() - tic
            tic = time.time()
            
        tokens.append(token.item())
        s = tokenizer.decode(tokens)
        print(s[skip:], end="", flush=True)
        skip = len(s)
    
    print(tokenizer.decode(tokens)[skip:], flush=True)
    gen_time = time.time() - tic
    
    print("\n" + "=" * 50)
    if len(tokens) > 0:
        prompt_tps = len(prompt_tokens) / prompt_time
        gen_tps = (len(tokens) - 1) / gen_time
        print(f"‚ö° Prompt: {prompt_tps:.3f} tokens/sec")
        print(f"‚ö° G√©n√©ration: {gen_tps:.3f} tokens/sec")
        print(f"üìä Tokens g√©n√©r√©s: {len(tokens)}")
    else:
        print("‚ùå Aucun token g√©n√©r√© pour ce prompt")


if __name__ == "__main__":
    main()
